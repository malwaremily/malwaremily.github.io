---
title: "Logging honeypots with BigQuery"
date: 2021-01-29T00:00:03+00:00
weight: 1
aliases: ["/forward-honeypot-logs"]
tags: ["honeypot logs", "logs", "gcp", "gcloud"]
author: "eeubanks"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
disableShare: false
cover:
    image: "/img/005-logs01.png" # image path/url
    alt: "TBD" # alt text
    caption: "<text>" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
comments: false
description: "Ingesting honeypot logs on GCP"
disableHLJS: true # to disable highlightjs
---

# Executive Summary
TLDR; I forwarded my honeypot data using a GCP golang client.

# Motive
I wanted to centralize my honeypot logs in Google Cloud Storage for monitoring and analysis within GCP services like BigQuery and Data Studio.

# How to Forward Docker Logs
Many of my honeypots are dockerized. Automating log forwarding of docker containers is the fastest way to get the bulk of my logs forwarded to GCP.

# Notes
My VMs were hosted in GCP and provisioned as EC2 instances which means that they do not come installed with the GCP Logging agent. VMs running in Google Kubernetes Engine or App Engine will have the GCP Logging agent already installed. [3]



# Auth
To authenticate to google use the following commands to (1) create a service account:
```
gcloud iam service-accounts create NAME
```
(2) grant permissions to the service account:
```
gcloud projects add-iam-policy-binding PROJECT_ID --member="serviceAccount:NAME@PROJECT_ID.iam.gserviceaccount.com" --role="roles/owner"
```
and (3) generate a key file. Be sure to replace fields in CAPS with their respective values:
```
gcloud iam service-accounts keys create FILE_NAME.json --iam-account=NAME@PROJECT_ID.iam.gserviceaccount.com
```
Now provide authentication credentials to the application by setting an environment variable. 
```
export GOOGLE_APPLICATION_CREDENTIALS="/home/user/Downloads/my-key.json"
```

Okay let's test this installation. We'll need a development environment.
```
go get -u cloud.google.com/go/logging
mkdir glogs
cd glogs/
go mod init glogs
go get cloud.google.com/go/storage
go list -m 
go mod tidy
touch main.go
code main.go
```
Put the following example code from google into `main.go`:
```
// Sample logging-quickstart writes a log entry to Cloud Logging.
package main

import (
        "context"
        "fmt"
        "log"

        "cloud.google.com/go/logging"
)

func main() {
        ctx := context.Background()

        // Sets your Google Cloud Platform project ID.
        projectID := "YOUR_PROJECT_ID"

        // Creates a client.
        client, err := logging.NewClient(ctx, projectID)
        if err != nil {
                log.Fatalf("Failed to create client: %v", err)
        }

        // Sets the name of the log to write to.
        logName := "my-log"

        // Selects the log to write to.
        logger := client.Logger(logName)

        // Sets the data to log.
        text := "Hello, world!"

        // Adds an entry to the log buffer.
        logger.Log(logging.Entry{Payload: text})

        // Closes the client and flushes the buffer to the Cloud Logging
        // service.
        if err := client.Close(); err != nil {
                log.Fatalf("Failed to close client: %v", err)
        }

        fmt.Printf("Logged: %v\n", text)
}
```

## Planning Log Collection
The honeynet will be small in an effort to keep the cost of this experiement low. Sending and storing logs will be added costs. Taking cost into account, the log collection strategy will be [minimalist](https://docs.graylog.org/en/4.0/pages/getting_started/planning.html). 

The use-case of honeypot log collection is to observe malicious behavioral patterns. For this reason, you may choose to only forward intelligence gathered by the honeypot. However, within the context of an enterprise, an administrator may wish to also monitor the health of the honeypot host in order to ensure the integrity and availability of data. 

Data retention is additional consideration. Again, in the context of an enterprise data retention policies may apply. Consider the type of data being stored and the frequency with which it will be queried. This will impact the type of storage used and cost (i.e. hot vs. cold storage). 

## Additional References:
* [1] https://cloud.google.com/logging/docs/reference/libraries#command-line
* [2] https://pkg.go.dev/cloud.google.com/go/storage
* [3] https://cloud.google.com/logging/docs/agent/logging/installation